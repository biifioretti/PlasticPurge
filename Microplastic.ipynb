{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Combate à Poluição Plástica nos Oceanos e Praias: Um Desafio de Machine Learning\n",
        "\n",
        "## Global Solution - 3ECR\n",
        "\n",
        "##Integrantes:\n",
        "- Bianca Fioretti dos Santos (RM96019)\n",
        "- Gustavo Kenzo Abe (RM 93944)\n",
        "- Greidimar Ferreira Lagares (RM 93827)\n",
        "\n",
        "\n",
        "\n",
        "### Descrição\n",
        "\n",
        "O dataset intitulado \"Global Microplastic Initiative\" (https://www.adventurescientists.org/microplastics.html) desenvolvido pela organização Adventure Scientists (https://www.adventurescientists.org/) é uma pesquisa com um dos maiores e mais diversos conjuntos de dados globais sobre poluição por microplásticos até o momento. De 2013 a 2017, a Adventure Scientists mobilizou milhares de voluntários treinados para ajudar a identificar a extensão da poluição por microplásticos em sistemas marinhos e de água doce em todo o mundo. Estes dados estão a ser utilizados por empresas, governos e indivíduos para limitar o desperdício de plástico e estudar seus efeitos no meio ambiente.\n",
        "\n",
        "Com este dataset podemos:\n",
        "- **Previsão da abundância de resíduos plásticos:** Desenvolver um modelo que preveja a abundância de resíduos plásticos em um determinado local com base em fatores ambientais como temperatura da água, salinidade e proximidade de assentamentos humanos.\n",
        "\n",
        "- **Identificação de fontes de poluição plástica:** Criar um modelo que identifique as prováveis fontes de poluição plástica em uma determinada área, considerando fatores como práticas de gestão de resíduos, atividades industriais e turismo costeiro.\n",
        "\n",
        "### Metodologia utilizada\n",
        "**Classificação**\n",
        "Escolhemos a classificação pois queremos prever a classe/categoria das analises coletadas de acordo com o local em que foram recolhidas pelos voluntarios. Acreditamos que esses dados serão de grande ajuda no projeto PlasticPurge uma vez que com estes dados podemos verificar quais locais possuem maior quantidade de microplásticos e utilizar este machine learning para decidir onde nossa embarcação deve atuar com mais urgência.\n",
        "\n",
        "Em nosso arquivo será utilizado o Algoritmo Random Forest e o Algoritmo KNN.\n"
      ],
      "metadata": {
        "id": "0PCfrTFSq44X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Importação de bibliotecas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Algoritmo Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "BUzutBBfwhnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação do dataframe\n",
        "\n",
        "Agora iremos criar um dataframe chamado \"df\" a partir dos dados do arquivo \"Microplastic_Data_AdventureScientists.csv\" anexado pelo grupo junto a entrega do código fonte. Este dataset pode ser encontrado no site https://www.adventurescientists.org/microplastics.html."
      ],
      "metadata": {
        "id": "-wQUgqT0zGB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/Faculdade/3º Ano/Global Solution/0211009/1.1/data/1-data/Microplastic_Data_AdventureScientists.csv')\n",
        "\n",
        "# Informações dos atributos (formato dos dados)\n",
        "df.info()\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "CYIWE1Lqz2LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estatísticas descritivas dos atributos\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "na9vSdkv12rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluindo colunas vazias\n",
        "df = df[['Sample Date', 'Latitude', 'Longitude', 'Total Pieces/L ']]\n",
        "df.columns"
      ],
      "metadata": {
        "id": "HoQXydX03zuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vizualização das informações do dataframe\n",
        "\n",
        "Agora iremos gerar gráficos e mapas para ter noção das localizações mais críticas de forma visual antes de partimos para nossas analíses preditivas. Aqui buscamos atender ao requisito \"Identificação de fontes de poluição plástica\", pois com os gráficos buscamos destacar os locais com maior quantidade de poluição dos oceanos."
      ],
      "metadata": {
        "id": "0T7Vkdh1BYPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vizualização da distribuição de microplásticos por localização\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(data=df, x='Longitude', y='Latitude', hue='Total Pieces/L ', palette='viridis')\n",
        "plt.title('Distribuição de Microplásticos por Localização')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.show()\n",
        "\n",
        "# Gerando mapas com os valores encontrados\n",
        "mapa = folium.Map(location=[df['Latitude'].mean(), df['Longitude'].mean()], zoom_start=2)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    quantidade = row['Total Pieces/L ']\n",
        "    cor = 'red' if quantidade > 100 else 'orange' if quantidade > 50 else 'yellow' if quantidade > 10 else 'green'\n",
        "    folium.CircleMarker(location=[row['Latitude'], row['Longitude']], radius=quantidade/10, color=cor, fill=True, fill_color=cor).add_to(mapa)\n",
        "\n",
        "mapa"
      ],
      "metadata": {
        "id": "_mwLw9EN5T-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação e separação dos dados de teste\n",
        "\n",
        "Agora para atender ao requisito \"Previsão da abundância de resíduos plásticos\", vamos realizar a nossa analise preditiva para saber onde nossa embarcação precisa atuar com mais urgência de acordo com os resultados."
      ],
      "metadata": {
        "id": "Dd0BAUegGqdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos dados\n",
        "X = df[['Latitude', 'Longitude']]\n",
        "y = df['Total Pieces/L ']\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "id": "ngtPHb3PHWPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação de dados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f'X_treino: {X_treino.shape}')\n",
        "print(f'X_teste: {X_teste.shape}')\n",
        "print(f'y_treino: {y_treino.shape}')\n",
        "print(f'y_teste: {y_teste.shape}')"
      ],
      "metadata": {
        "id": "qG_X_wVcNdcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo Random Forest\n",
        "modelo1 = RandomForestClassifier(random_state=42)\n",
        "modelo1.fit(X_treino, y_treino)\n",
        "\n",
        "# Gerar analise preditiva\n",
        "y_preditivo_RF = modelo1.predict(X_teste)\n",
        "y_preditivo_RF"
      ],
      "metadata": {
        "id": "6vlErzsmKi4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilização KNN para treinamento\n",
        "modelo2 = KNeighborsClassifier()\n",
        "modelo2.fit(X_treino, y_treino)\n",
        "\n",
        "# Gerar analise preditiva\n",
        "y_preditivo_KNN = modelo2.predict(X_teste)\n",
        "y_preditivo_KNN"
      ],
      "metadata": {
        "id": "-ho2nId7s4zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados\n",
        "\n",
        "A seguir, vamos realizar o cálculo para saber a acuracia dos modelos criados e calcular qual possue maior eficácia na predição dos eventos."
      ],
      "metadata": {
        "id": "_Hk-J8R9rebZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo Random Forest\n",
        "acuracia1 = 100 *  (accuracy_score(y_teste, y_preditivo_RF))\n",
        "print(f'A acurácia do modelo Random Forest é: {acuracia1:.2f}%')"
      ],
      "metadata": {
        "id": "xNe5QyTALkOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo KNN\n",
        "acuracia2 = 100 *  (accuracy_score(y_teste, y_preditivo_KNN))\n",
        "print(f'A acurácia do modelo KNN é: {acuracia2:.2f}%')"
      ],
      "metadata": {
        "id": "onY4vhgetS-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusões\n",
        "\n",
        "Podemos observar que ambos os algoritmos utilizados desempenharam uma baixa acurácia mesmo utilizando dois algoritmos muito eficazes para nosso objetivo. Isso se dá ao fato de nosso dataset possuir poucas variáveis.\n",
        "A inclusão de mais variáveis preditivas além da latitude e longitude utilizados, como temperatura da água, salinidade, distâncias até a costa ou até cidades próximas, densidade populacional, etc, podem aumentar a precisão do modelo o que o tornaria mais confiavel para a utilização em nosso projeto PlasticPurge."
      ],
      "metadata": {
        "id": "JPd-CyCwrUY4"
      }
    }
  ]
}